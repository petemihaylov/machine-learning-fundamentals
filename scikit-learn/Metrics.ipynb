{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Card Fraud Detection\n",
    "#### https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "df = pd.read_csv(\"./creditcard.csv\")[:80_000]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shapes of X=(80000, 28) y=(80000,), #Fraud Cases=196'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values\n",
    "\n",
    "f\"Shapes of X={X.shape} y={y.shape}, #Fraud Cases={y.sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)\n",
    "mod.fit(X, y).predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petemihaylov/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},\n",
       "                                          {...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit='precision', return_train_score=True,\n",
       "             scoring={'precision': make_scorer(precision_score),\n",
       "                      'recall_score': make_scorer(recall_score)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000),\n",
    "    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},\n",
    "    scoring={'precision': make_scorer(precision_score), 'recall_score': make_scorer(recall_score)},\n",
    "    refit='precision',\n",
    "    return_train_score=True,\n",
    "    cv=7,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7602040816326531"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y, grid.predict(X)) # Given that I predict fraud how accurate am I?\n",
    "recall_score(y, grid.predict(X)) # Did I get all the fraud cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>split0_train_recall_score</th>\n",
       "      <th>split1_train_recall_score</th>\n",
       "      <th>split2_train_recall_score</th>\n",
       "      <th>split3_train_recall_score</th>\n",
       "      <th>split4_train_recall_score</th>\n",
       "      <th>split5_train_recall_score</th>\n",
       "      <th>split6_train_recall_score</th>\n",
       "      <th>mean_train_recall_score</th>\n",
       "      <th>std_train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.117415</td>\n",
       "      <td>0.224456</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>{0: 1, 1: 1.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.0}}</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.628401</td>\n",
       "      <td>0.058482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.031042</td>\n",
       "      <td>0.235943</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>{0: 1, 1: 1.6551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.6551724137931034}}</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.672619</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.697279</td>\n",
       "      <td>0.061319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.009762</td>\n",
       "      <td>0.144431</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>{0: 1, 1: 2.310344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.310344827586207}}</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.051975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.912665</td>\n",
       "      <td>0.126548</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>{0: 1, 1: 2.9655172413793105}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.9655172413793105}}</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.779762</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.756803</td>\n",
       "      <td>0.047023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.837731</td>\n",
       "      <td>0.120331</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>{0: 1, 1: 3.6206896551724137}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.6206896551724137}}</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.037876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.807956</td>\n",
       "      <td>0.084218</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>{0: 1, 1: 4.275862068965517}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.275862068965517}}</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779762</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.028228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.760501</td>\n",
       "      <td>0.106206</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>{0: 1, 1: 4.931034482758621}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.931034482758621}}</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.022498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.628679</td>\n",
       "      <td>0.104905</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>{0: 1, 1: 5.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.586206896551724}}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.020967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.783090</td>\n",
       "      <td>0.129498</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>{0: 1, 1: 6.241379310344827}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.241379310344827}}</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.834184</td>\n",
       "      <td>0.016964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.830100</td>\n",
       "      <td>0.145683</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>{0: 1, 1: 6.896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.896551724137931}}</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.844388</td>\n",
       "      <td>0.015726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.819705</td>\n",
       "      <td>0.115437</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>{0: 1, 1: 7.551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.551724137931034}}</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.016134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.776611</td>\n",
       "      <td>0.103251</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>{0: 1, 1: 8.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.206896551724139}}</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.016044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.770667</td>\n",
       "      <td>0.112424</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>{0: 1, 1: 8.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.862068965517242}}</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.852041</td>\n",
       "      <td>0.017260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.756201</td>\n",
       "      <td>0.089515</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>{0: 1, 1: 9.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.517241379310345}}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.853741</td>\n",
       "      <td>0.017092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.675482</td>\n",
       "      <td>0.077704</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>{0: 1, 1: 10.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.172413793103448}}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.017998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.583142</td>\n",
       "      <td>0.173452</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>{0: 1, 1: 10.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.827586206896552}}</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.858844</td>\n",
       "      <td>0.018198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.751684</td>\n",
       "      <td>0.141337</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>{0: 1, 1: 11.482758620689655}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.482758620689655}}</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.859694</td>\n",
       "      <td>0.017674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.832100</td>\n",
       "      <td>0.111336</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>{0: 1, 1: 12.137931034482758}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.137931034482758}}</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.014024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.815435</td>\n",
       "      <td>0.184717</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>{0: 1, 1: 12.793103448275861}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.793103448275861}}</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.014024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.850387</td>\n",
       "      <td>0.159352</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>{0: 1, 1: 13.448275862068964}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.448275862068964}}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.013499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.848264</td>\n",
       "      <td>0.161918</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>{0: 1, 1: 14.103448275862068}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.103448275862068}}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.865646</td>\n",
       "      <td>0.013816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.797168</td>\n",
       "      <td>0.101054</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>{0: 1, 1: 14.758620689655173}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.758620689655173}}</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.014826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.656645</td>\n",
       "      <td>0.091858</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>{0: 1, 1: 15.413793103448276}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.413793103448276}}</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.014580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.651927</td>\n",
       "      <td>0.210801</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>{0: 1, 1: 16.06896551724138}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.06896551724138}}</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.871599</td>\n",
       "      <td>0.013063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.728590</td>\n",
       "      <td>0.161297</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>{0: 1, 1: 16.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.724137931034484}}</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.871599</td>\n",
       "      <td>0.013063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.869353</td>\n",
       "      <td>0.164035</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>{0: 1, 1: 17.379310344827587}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.379310344827587}}</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.872449</td>\n",
       "      <td>0.013816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.822255</td>\n",
       "      <td>0.132891</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>{0: 1, 1: 18.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.03448275862069}}</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.873299</td>\n",
       "      <td>0.013391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.791591</td>\n",
       "      <td>0.182042</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>{0: 1, 1: 18.689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.689655172413794}}</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.772054</td>\n",
       "      <td>0.130062</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>{0: 1, 1: 19.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.344827586206897}}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.624268</td>\n",
       "      <td>0.068137</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.117415      0.224456         0.010706        0.003305   \n",
       "1        1.031042      0.235943         0.011126        0.003730   \n",
       "2        1.009762      0.144431         0.007915        0.003632   \n",
       "3        0.912665      0.126548         0.008063        0.003702   \n",
       "4        0.837731      0.120331         0.006994        0.002505   \n",
       "5        0.807956      0.084218         0.007025        0.003516   \n",
       "6        0.760501      0.106206         0.006242        0.002039   \n",
       "7        0.628679      0.104905         0.005519        0.002036   \n",
       "8        0.783090      0.129498         0.006259        0.002300   \n",
       "9        0.830100      0.145683         0.006875        0.003158   \n",
       "10       0.819705      0.115437         0.007419        0.004303   \n",
       "11       0.776611      0.103251         0.005017        0.001175   \n",
       "12       0.770667      0.112424         0.007563        0.002961   \n",
       "13       0.756201      0.089515         0.007488        0.003058   \n",
       "14       0.675482      0.077704         0.006736        0.002413   \n",
       "15       0.583142      0.173452         0.005025        0.001629   \n",
       "16       0.751684      0.141337         0.008399        0.003599   \n",
       "17       0.832100      0.111336         0.005046        0.000810   \n",
       "18       0.815435      0.184717         0.006981        0.003523   \n",
       "19       0.850387      0.159352         0.004757        0.000410   \n",
       "20       0.848264      0.161918         0.009991        0.003020   \n",
       "21       0.797168      0.101054         0.008773        0.004949   \n",
       "22       0.656645      0.091858         0.006381        0.002677   \n",
       "23       0.651927      0.210801         0.006438        0.002271   \n",
       "24       0.728590      0.161297         0.007926        0.002839   \n",
       "25       0.869353      0.164035         0.008179        0.003348   \n",
       "26       0.822255      0.132891         0.008372        0.002367   \n",
       "27       0.791591      0.182042         0.010005        0.003742   \n",
       "28       0.772054      0.130062         0.005991        0.002846   \n",
       "29       0.624268      0.068137         0.004092        0.000518   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 1.0}   \n",
       "1   {0: 1, 1: 1.6551724137931034}   \n",
       "2    {0: 1, 1: 2.310344827586207}   \n",
       "3   {0: 1, 1: 2.9655172413793105}   \n",
       "4   {0: 1, 1: 3.6206896551724137}   \n",
       "5    {0: 1, 1: 4.275862068965517}   \n",
       "6    {0: 1, 1: 4.931034482758621}   \n",
       "7    {0: 1, 1: 5.586206896551724}   \n",
       "8    {0: 1, 1: 6.241379310344827}   \n",
       "9    {0: 1, 1: 6.896551724137931}   \n",
       "10   {0: 1, 1: 7.551724137931034}   \n",
       "11   {0: 1, 1: 8.206896551724139}   \n",
       "12   {0: 1, 1: 8.862068965517242}   \n",
       "13   {0: 1, 1: 9.517241379310345}   \n",
       "14  {0: 1, 1: 10.172413793103448}   \n",
       "15  {0: 1, 1: 10.827586206896552}   \n",
       "16  {0: 1, 1: 11.482758620689655}   \n",
       "17  {0: 1, 1: 12.137931034482758}   \n",
       "18  {0: 1, 1: 12.793103448275861}   \n",
       "19  {0: 1, 1: 13.448275862068964}   \n",
       "20  {0: 1, 1: 14.103448275862068}   \n",
       "21  {0: 1, 1: 14.758620689655173}   \n",
       "22  {0: 1, 1: 15.413793103448276}   \n",
       "23   {0: 1, 1: 16.06896551724138}   \n",
       "24  {0: 1, 1: 16.724137931034484}   \n",
       "25  {0: 1, 1: 17.379310344827587}   \n",
       "26   {0: 1, 1: 18.03448275862069}   \n",
       "27  {0: 1, 1: 18.689655172413794}   \n",
       "28  {0: 1, 1: 19.344827586206897}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 1.0}}               0.687500   \n",
       "1   {'class_weight': {0: 1, 1: 1.6551724137931034}}               0.722222   \n",
       "2    {'class_weight': {0: 1, 1: 2.310344827586207}}               0.736842   \n",
       "3   {'class_weight': {0: 1, 1: 2.9655172413793105}}               0.814815   \n",
       "4   {'class_weight': {0: 1, 1: 3.6206896551724137}}               0.833333   \n",
       "5    {'class_weight': {0: 1, 1: 4.275862068965517}}               0.838710   \n",
       "6    {'class_weight': {0: 1, 1: 4.931034482758621}}               0.838710   \n",
       "7    {'class_weight': {0: 1, 1: 5.586206896551724}}               0.812500   \n",
       "8    {'class_weight': {0: 1, 1: 6.241379310344827}}               0.787879   \n",
       "9    {'class_weight': {0: 1, 1: 6.896551724137931}}               0.787879   \n",
       "10   {'class_weight': {0: 1, 1: 7.551724137931034}}               0.794118   \n",
       "11   {'class_weight': {0: 1, 1: 8.206896551724139}}               0.794118   \n",
       "12   {'class_weight': {0: 1, 1: 8.862068965517242}}               0.794118   \n",
       "13   {'class_weight': {0: 1, 1: 9.517241379310345}}               0.750000   \n",
       "14  {'class_weight': {0: 1, 1: 10.172413793103448}}               0.750000   \n",
       "15  {'class_weight': {0: 1, 1: 10.827586206896552}}               0.729730   \n",
       "16  {'class_weight': {0: 1, 1: 11.482758620689655}}               0.710526   \n",
       "17  {'class_weight': {0: 1, 1: 12.137931034482758}}               0.710526   \n",
       "18  {'class_weight': {0: 1, 1: 12.793103448275861}}               0.710526   \n",
       "19  {'class_weight': {0: 1, 1: 13.448275862068964}}               0.675000   \n",
       "20  {'class_weight': {0: 1, 1: 14.103448275862068}}               0.675000   \n",
       "21  {'class_weight': {0: 1, 1: 14.758620689655173}}               0.642857   \n",
       "22  {'class_weight': {0: 1, 1: 15.413793103448276}}               0.642857   \n",
       "23   {'class_weight': {0: 1, 1: 16.06896551724138}}               0.586957   \n",
       "24  {'class_weight': {0: 1, 1: 16.724137931034484}}               0.586957   \n",
       "25  {'class_weight': {0: 1, 1: 17.379310344827587}}               0.574468   \n",
       "26   {'class_weight': {0: 1, 1: 18.03448275862069}}               0.540000   \n",
       "27  {'class_weight': {0: 1, 1: 18.689655172413794}}               0.540000   \n",
       "28  {'class_weight': {0: 1, 1: 19.344827586206897}}               0.500000   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}               0.490909   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                0.460000               1.000000               0.937500  ...   \n",
       "1                0.470588               1.000000               0.944444  ...   \n",
       "2                0.480769               1.000000               0.947368  ...   \n",
       "3                0.480769               1.000000               0.947368  ...   \n",
       "4                0.480769               1.000000               0.950000  ...   \n",
       "5                0.480769               0.833333               0.904762  ...   \n",
       "6                0.480769               0.857143               0.904762  ...   \n",
       "7                0.480769               0.857143               0.869565  ...   \n",
       "8                0.480769               0.888889               0.869565  ...   \n",
       "9                0.480769               0.888889               0.869565  ...   \n",
       "10               0.480769               0.888889               0.869565  ...   \n",
       "11               0.480769               0.888889               0.833333  ...   \n",
       "12               0.480769               0.888889               0.833333  ...   \n",
       "13               0.480769               0.888889               0.833333  ...   \n",
       "14               0.480769               0.888889               0.833333  ...   \n",
       "15               0.480769               0.888889               0.833333  ...   \n",
       "16               0.480769               0.888889               0.833333  ...   \n",
       "17               0.480769               0.900000               0.800000  ...   \n",
       "18               0.480769               0.900000               0.800000  ...   \n",
       "19               0.471698               0.900000               0.800000  ...   \n",
       "20               0.471698               0.900000               0.800000  ...   \n",
       "21               0.471698               0.900000               0.800000  ...   \n",
       "22               0.471698               0.900000               0.807692  ...   \n",
       "23               0.471698               0.900000               0.807692  ...   \n",
       "24               0.462963               0.900000               0.807692  ...   \n",
       "25               0.446429               0.900000               0.807692  ...   \n",
       "26               0.446429               0.900000               0.807692  ...   \n",
       "27               0.423729               0.900000               0.807692  ...   \n",
       "28               0.409836               0.900000               0.814815  ...   \n",
       "29               0.409836               0.900000               0.814815  ...   \n",
       "\n",
       "    rank_test_recall_score  split0_train_recall_score  \\\n",
       "0                       30                   0.625000   \n",
       "1                       29                   0.672619   \n",
       "2                       28                   0.690476   \n",
       "3                       27                   0.732143   \n",
       "4                       26                   0.761905   \n",
       "5                       25                   0.797619   \n",
       "6                       24                   0.815476   \n",
       "7                       23                   0.833333   \n",
       "8                       21                   0.833333   \n",
       "9                       21                   0.839286   \n",
       "10                      20                   0.839286   \n",
       "11                      19                   0.839286   \n",
       "12                      14                   0.839286   \n",
       "13                      14                   0.845238   \n",
       "14                      14                   0.845238   \n",
       "15                      14                   0.845238   \n",
       "16                      14                   0.851190   \n",
       "17                      12                   0.851190   \n",
       "18                      12                   0.851190   \n",
       "19                       9                   0.851190   \n",
       "20                       9                   0.851190   \n",
       "21                       9                   0.851190   \n",
       "22                       3                   0.857143   \n",
       "23                       3                   0.869048   \n",
       "24                       3                   0.869048   \n",
       "25                       3                   0.869048   \n",
       "26                       3                   0.869048   \n",
       "27                       3                   0.869048   \n",
       "28                       1                   0.869048   \n",
       "29                       1                   0.869048   \n",
       "\n",
       "    split1_train_recall_score  split2_train_recall_score  \\\n",
       "0                    0.755952                   0.589286   \n",
       "1                    0.827381                   0.666667   \n",
       "2                    0.845238                   0.702381   \n",
       "3                    0.857143                   0.726190   \n",
       "4                    0.857143                   0.767857   \n",
       "5                    0.857143                   0.773810   \n",
       "6                    0.857143                   0.791667   \n",
       "7                    0.869048                   0.815476   \n",
       "8                    0.869048                   0.821429   \n",
       "9                    0.875000                   0.833333   \n",
       "10                   0.875000                   0.833333   \n",
       "11                   0.875000                   0.833333   \n",
       "12                   0.875000                   0.833333   \n",
       "13                   0.875000                   0.833333   \n",
       "14                   0.875000                   0.839286   \n",
       "15                   0.875000                   0.845238   \n",
       "16                   0.875000                   0.845238   \n",
       "17                   0.875000                   0.851190   \n",
       "18                   0.875000                   0.851190   \n",
       "19                   0.875000                   0.857143   \n",
       "20                   0.875000                   0.857143   \n",
       "21                   0.875000                   0.857143   \n",
       "22                   0.875000                   0.857143   \n",
       "23                   0.875000                   0.863095   \n",
       "24                   0.875000                   0.863095   \n",
       "25                   0.875000                   0.863095   \n",
       "26                   0.875000                   0.869048   \n",
       "27                   0.875000                   0.869048   \n",
       "28                   0.875000                   0.869048   \n",
       "29                   0.875000                   0.869048   \n",
       "\n",
       "    split3_train_recall_score  split4_train_recall_score  \\\n",
       "0                    0.607143                   0.553571   \n",
       "1                    0.678571                   0.613095   \n",
       "2                    0.726190                   0.678571   \n",
       "3                    0.738095                   0.702381   \n",
       "4                    0.755952                   0.726190   \n",
       "5                    0.785714                   0.767857   \n",
       "6                    0.797619                   0.791667   \n",
       "7                    0.833333                   0.803571   \n",
       "8                    0.845238                   0.815476   \n",
       "9                    0.851190                   0.821429   \n",
       "10                   0.851190                   0.821429   \n",
       "11                   0.857143                   0.827381   \n",
       "12                   0.857143                   0.827381   \n",
       "13                   0.863095                   0.827381   \n",
       "14                   0.869048                   0.827381   \n",
       "15                   0.869048                   0.827381   \n",
       "16                   0.869048                   0.827381   \n",
       "17                   0.869048                   0.839286   \n",
       "18                   0.869048                   0.839286   \n",
       "19                   0.869048                   0.839286   \n",
       "20                   0.869048                   0.845238   \n",
       "21                   0.875000                   0.845238   \n",
       "22                   0.880952                   0.845238   \n",
       "23                   0.880952                   0.845238   \n",
       "24                   0.880952                   0.845238   \n",
       "25                   0.880952                   0.845238   \n",
       "26                   0.880952                   0.845238   \n",
       "27                   0.880952                   0.851190   \n",
       "28                   0.880952                   0.851190   \n",
       "29                   0.880952                   0.851190   \n",
       "\n",
       "    split5_train_recall_score  split6_train_recall_score  \\\n",
       "0                    0.636905                   0.630952   \n",
       "1                    0.708333                   0.714286   \n",
       "2                    0.750000                   0.750000   \n",
       "3                    0.779762                   0.761905   \n",
       "4                    0.791667                   0.767857   \n",
       "5                    0.809524                   0.779762   \n",
       "6                    0.821429                   0.791667   \n",
       "7                    0.827381                   0.803571   \n",
       "8                    0.833333                   0.821429   \n",
       "9                    0.839286                   0.851190   \n",
       "10                   0.851190                   0.857143   \n",
       "11                   0.863095                   0.857143   \n",
       "12                   0.869048                   0.863095   \n",
       "13                   0.869048                   0.863095   \n",
       "14                   0.875000                   0.869048   \n",
       "15                   0.880952                   0.869048   \n",
       "16                   0.880952                   0.869048   \n",
       "17                   0.880952                   0.869048   \n",
       "18                   0.880952                   0.869048   \n",
       "19                   0.880952                   0.869048   \n",
       "20                   0.886905                   0.875000   \n",
       "21                   0.886905                   0.880952   \n",
       "22                   0.886905                   0.880952   \n",
       "23                   0.886905                   0.880952   \n",
       "24                   0.886905                   0.880952   \n",
       "25                   0.886905                   0.886905   \n",
       "26                   0.886905                   0.886905   \n",
       "27                   0.886905                   0.886905   \n",
       "28                   0.886905                   0.886905   \n",
       "29                   0.886905                   0.886905   \n",
       "\n",
       "    mean_train_recall_score  std_train_recall_score  \n",
       "0                  0.628401                0.058482  \n",
       "1                  0.697279                0.061319  \n",
       "2                  0.734694                0.051975  \n",
       "3                  0.756803                0.047023  \n",
       "4                  0.775510                0.037876  \n",
       "5                  0.795918                0.028228  \n",
       "6                  0.809524                0.022498  \n",
       "7                  0.826531                0.020967  \n",
       "8                  0.834184                0.016964  \n",
       "9                  0.844388                0.015726  \n",
       "10                 0.846939                0.016134  \n",
       "11                 0.850340                0.016044  \n",
       "12                 0.852041                0.017260  \n",
       "13                 0.853741                0.017092  \n",
       "14                 0.857143                0.017998  \n",
       "15                 0.858844                0.018198  \n",
       "16                 0.859694                0.017674  \n",
       "17                 0.862245                0.014024  \n",
       "18                 0.862245                0.014024  \n",
       "19                 0.863095                0.013499  \n",
       "20                 0.865646                0.013816  \n",
       "21                 0.867347                0.014826  \n",
       "22                 0.869048                0.014580  \n",
       "23                 0.871599                0.013063  \n",
       "24                 0.871599                0.013063  \n",
       "25                 0.872449                0.013816  \n",
       "26                 0.873299                0.013391  \n",
       "27                 0.874150                0.011659  \n",
       "28                 0.874150                0.011659  \n",
       "29                 0.874150                0.011659  \n",
       "\n",
       "[30 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_test_recall'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_test_recall'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ecc8d05c3272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_test_precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_class_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_test_recall'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "for score in ['mean_test_recall', 'mean_test_precision']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']], df[score], label=score)\n",
    "    \n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
